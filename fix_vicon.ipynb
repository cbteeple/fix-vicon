{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"legend.frameon\"] = False\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "with open('save_path.yaml') as f:\n",
    "    save_paths = yaml.load(f)\n",
    "\n",
    "data_folder_base  = os.path.join(save_paths.get('data_path',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_select = 'harder'\n",
    "number_of_markers = 2\n",
    "vicon_sample_rate = 500 # Hz\n",
    "\n",
    "save_pickles = True\n",
    "save_csvs    = True\n",
    "\n",
    "if file_select == 'hard':\n",
    "    file_names = ['ihm_rot_gait_foam_3_Trajectories_500']\n",
    "    \n",
    "elif file_select == 'harder':\n",
    "    file_names = ['ihm_rot_gait_box_3_Trajectories_500']\n",
    "    \n",
    "elif file_select == 'easy':\n",
    "    file_names = ['ihm_rot_gait_yellowcup_Trajectories_500',\n",
    "                  'ihm_rot_gait_orangecup2_Trajectories_500']\n",
    "    \n",
    "elif file_select == 'incept':\n",
    "    file_names = ['ihm_rot_gait_foam_3_Trajectories_500_collapsed']\n",
    "    \n",
    "else:\n",
    "    file_names = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the data for future use.\n",
    "def pickle_data(out_data, filename):\n",
    "    out_file = os.path.join(data_folder_base,filename+'_fixed.pkl')\n",
    "\n",
    "    dirname = os.path.dirname(out_file)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Pickling...\")\n",
    "    print('file: %s'%(filename))\n",
    "    with open(out_file, 'w') as f:\n",
    "        pickle.dump(out_data, f)\n",
    "    print(\"Pickling...DONE!\")\n",
    "            \n",
    "            \n",
    "def save_csv(out_data_all_in_one, filename, header=None):\n",
    "    out_file = os.path.join(data_folder_base,filename+'_fixed.csv')\n",
    "\n",
    "    dirname = os.path.dirname(out_file)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Saving CSV...\")\n",
    "    print('file: %s'%(filename))\n",
    "    with open(out_file, 'w') as f:\n",
    "        if header is not None:\n",
    "            f.write(header+'\\n')\n",
    "        np.savetxt(f, out_data_all_in_one, delimiter=',')\n",
    "    print(\"Saving CSV...DONE!\")\n",
    "        \n",
    "        \n",
    "def plot_all(data_collapsed,file_idx,number_of_markers):\n",
    "    # plot the points in 3D and in 2D\n",
    "        fig = plt.figure(1+file_idx*2)\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        for mark_idx in range(number_of_markers):\n",
    "            ax.plot(data_collapsed[:,0+mark_idx*3],\n",
    "                     data_collapsed[:,1+mark_idx*3],\n",
    "                     data_collapsed[:,2+mark_idx*3])\n",
    "        plt.show()\n",
    "            \n",
    "        fig2 = plt.figure(2+file_idx*2)\n",
    "        plt.plot(data_collapsed)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_sequential(pos, number_of_markers):\n",
    "    pos_fix=np.zeros(pos.shape)\n",
    "\n",
    "    pos_fix[0,:] = pos[0,:]\n",
    "\n",
    "    for idx, curr_row in enumerate(pos[1:,:]):\n",
    "        idx +=1\n",
    "        last_row = pos_fix[idx-1,:]\n",
    "\n",
    "        # for every point in the current row, find the norm with all points from the last row\n",
    "        correct_idx = np.zeros((number_of_markers,1))\n",
    "        for i in range(number_of_markers):\n",
    "            norm = np.zeros((number_of_markers,1))\n",
    "            curr_pt = curr_row[i*3: i*3 +3]\n",
    "            #print(curr_pt)\n",
    "            # for each point in the last row, find the norm with the current point\n",
    "            for j in range(number_of_markers):\n",
    "                #print(last_row[j*3: j*3 +3])\n",
    "                diff= curr_pt - last_row[j*3: j*3 +3]\n",
    "                norm[j] = np.linalg.norm(diff)\n",
    "\n",
    "            correct_idx[i]=np.argmin(norm)\n",
    "\n",
    "        new_idx = [0,1,2]+correct_idx*3\n",
    "        new_idx = new_idx.ravel().astype(int)\n",
    "        curr_row = curr_row[new_idx]\n",
    "\n",
    "        pos_fix[idx,:] = curr_row\n",
    "\n",
    "    #plot_all(pos_fix,3,number_of_markers)\n",
    "    \n",
    "    return pos_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_all = []\n",
    "for file_name in file_names:\n",
    "    full_filename = os.path.join(data_folder_base,file_name+'.csv')\n",
    "    with open(full_filename) as f:\n",
    "        # use safe_load instead of load\n",
    "        raw_data = np.genfromtxt(f, skip_header=5, delimiter=',')\n",
    "        raw_data\n",
    "    \n",
    "    print(raw_data.shape)\n",
    "    print(raw_data[0,:])\n",
    "    raw_data_all.append(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of 'nan' and match up columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_out = []\n",
    "\n",
    "for file_idx, curr_raw_data in enumerate(raw_data_all):\n",
    "    print(\"\")\n",
    "    print(file_names[file_idx])\n",
    "    data = curr_raw_data[:,2:]\n",
    "    frame_numbers = curr_raw_data[:,0]\n",
    "    time = (frame_numbers-1)*1.0/vicon_sample_rate\n",
    "    \n",
    "    not_divisible_by_3 = np.mod(data.shape[1],3)\n",
    "    if not_divisible_by_3:\n",
    "        print(\"The number of columns isn't divisible by 3. Are you missing an axis???\")\n",
    "    \n",
    "    else:\n",
    "        num_points = data.shape[1]/3.0\n",
    "        num_point_cols = number_of_markers*3\n",
    "        \n",
    "        frames_to_skip = []\n",
    "        num_merged_frames  = 0\n",
    "        \n",
    "        print(\"There are %d tracking columns from vicon to deal with\"%(num_points))\n",
    "        \n",
    "        data_collapsed=np.zeros((data.shape[0],3*number_of_markers))\n",
    "        for idx,row in enumerate(np.nditer(data, flags=['external_loop'], order='C')):\n",
    "            row_collapsed = row[np.logical_not(np.isnan(row))]\n",
    "            \n",
    "            # If the number of points in the frame matches what we expect, use them!\n",
    "            if row_collapsed.size == num_point_cols: \n",
    "                data_collapsed[idx,:] = row_collapsed\n",
    "                            \n",
    "            # If there are too many points in a frame,\n",
    "            # find the closest N points to the previous frame\n",
    "            elif  row_collapsed.size > num_point_cols:\n",
    "                frames_to_skip.append(idx) # This is temporary\n",
    "                \n",
    "            # If there are too few points in the frame, delete the frame.\n",
    "            else:\n",
    "                frames_to_skip.append(idx)\n",
    "        \n",
    "        # Delete frames that need to be deleted\n",
    "        data_collapsed   = np.delete(data_collapsed, frames_to_skip, 0)\n",
    "        frames_collapsed = np.delete(frame_numbers, frames_to_skip, 0)\n",
    "        time_collapsed   = np.delete(time, frames_to_skip, 0)\n",
    "        \n",
    "        # Print out some statistics\n",
    "        skip_percent = float(len(frames_to_skip))/data.shape[0]*100\n",
    "        merge_percent = float(num_merged_frames)/data.shape[0]*100\n",
    "        print(\"\")\n",
    "        print(\"Deleted %d frames, which is %0.3f\"%(len(frames_to_skip), skip_percent)+\"% of all data\")\n",
    "        print(\"Merged %d frames, which is %0.3f\"%(num_merged_frames, merge_percent)+\"% of all data\")\n",
    "\n",
    "        # Fix sequential data points to make sure they don't jump around\n",
    "        print(\"\")\n",
    "        print('Fixing sequential data jumping issues')\n",
    "        data_collapsed = fix_sequential(data_collapsed, number_of_markers)\n",
    "        \n",
    "        # Package the data in a native python dictionary for use later\n",
    "        out = dict()\n",
    "        out['position']=data_collapsed.tolist()\n",
    "        out['frame']=frames_collapsed.tolist()\n",
    "        out['time']=time_collapsed.tolist()\n",
    "        out['num_frames']=frames_collapsed.size\n",
    "        out['start_time']=time_collapsed[0]\n",
    "        out['end_time']=time_collapsed[-1]\n",
    "        \n",
    "                \n",
    "        print(\"\")\n",
    "        print(\"Time: %0.3f sec to %0.3f sec\"%(out['start_time'],out['end_time']))\n",
    "        print(\"      %0.3f min to %0.3f min\"%(out['start_time']/60.0,out['end_time']/60.0))\n",
    "                \n",
    "        plot_all(data_collapsed,file_idx,number_of_markers)\n",
    "        file_name_out = file_names[file_idx]\n",
    "        # Pickle the data for use later\n",
    "        if save_pickles:\n",
    "            pickle_data(out, file_name_out)\n",
    "        \n",
    "        if save_csvs:\n",
    "            all_in_one = data_collapsed\n",
    "            all_in_one = np.insert(all_in_one,0,time_collapsed, axis=1)\n",
    "            all_in_one = np.insert(all_in_one,0,frames_collapsed, axis=1)\n",
    "\n",
    "            header = '\\n'*4\n",
    "            header += 'Frame,Time'\n",
    "            for i in range(number_of_markers):\n",
    "                header+=\",X%d,Y%d,Z%d\"%(i,i,i)\n",
    "            save_csv(all_in_one, file_name_out, header = header)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
